{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"yayoi_study.ipynb","version":"0.3.2","views":{},"default_view":{},"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"wJ92Cl8GeT3W","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"output_extras":[{"item_id":66},{"item_id":107}],"base_uri":"https://localhost:8080/","height":1838},"outputId":"26298433-77ba-4b5e-b691-e18d13279585","executionInfo":{"status":"ok","timestamp":1521799470052,"user_tz":-540,"elapsed":2117130,"user":{"displayName":"赤西マロン","photoUrl":"//lh6.googleusercontent.com/-KhUeandtJaM/AAAAAAAAAAI/AAAAAAAAAEk/QrbgcTNc53o/s50-c-k-no/photo.jpg","userId":"112493323667235130589"}}},"cell_type":"code","source":["import sys\n","import json\n","import cv2\n","import random\n","import numpy as np\n","import tensorflow as tf\n","import tensorflow.python.platform\n","\n","# 識別ラベルの数\n","NUM_CLASSES = 13\n","# 学習する時の画像のサイズ(px)\n","IMAGE_SIZE = 56\n","# 画像の次元数\n","IMAGE_PIXELS = IMAGE_SIZE*IMAGE_SIZE*3\n","\n","# 学習に必要なデータのpathや学習の規模を設定\n","# 学習用データ\n","train_data = \"./files/study.json\"\n","# 検証用テストデータ\n","test_data = './files/test.json'\n","# データを置いてあるフォルダ\n","train_dir = './files'\n","# 1回の学習で何枚の画像を使うか\n","batch_size = 3000\n","# 学習率、小さすぎると学習が進まないし、大きすぎても誤差が収束しなかったり発散したりしてダメとか\n","learning_rate = 1e-4\n","\n","# AIの学習モデル部分(ニューラルネットワーク)を作成する\n","# images_placeholder: 画像のplaceholder, keep_prob: dropout率のplace_holderが引数になり\n","# 入力画像に対して、各ラベルの確率を出力して返す\n","def inference(images_placeholder, keep_prob):\n","\n","    # 重みを標準偏差0.1の正規分布で初期化する\n","    def weight_variable(shape):\n","        initial = tf.truncated_normal(shape, stddev=0.1)\n","        return tf.Variable(initial)\n","\n","    # バイアスを標準偏差0.1の正規分布で初期化する\n","    def bias_variable(shape):\n","        initial = tf.constant(0.1, shape=shape)\n","        return tf.Variable(initial)\n","\n","    # 畳み込み層を作成する\n","    def conv2d(x, W):\n","        return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n","\n","    # プーリング層を作成する\n","    def max_pool_2x2(x):\n","        return tf.nn.max_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n","\n","    # ベクトル形式で入力されてきた画像データを指定サイズに戻す(?)。\n","    # 今回はカラー画像なので3(モノクロだと1)\n","    x_image = tf.reshape(images_placeholder, [-1, IMAGE_SIZE, IMAGE_SIZE, 3])\n","\n","    # 畳み込み層第1レイヤーを作成\n","    with tf.name_scope('conv1') as scope:\n","        # 引数は[width, height, input, filters]。\n","        # 5px*5pxの範囲で画像をフィルターしている。今回はカラー画像なのでinputは3?\n","        # 32個の特徴を検出する\n","        W_conv1 = weight_variable([5, 5, 3, 32])\n","        # バイアスの数値を代入\n","        b_conv1 = bias_variable([32])\n","        # 特徴として検出した有用そうな部分は残し、特徴として使えなさそうな部分は\n","        # 0として、特徴として扱わないようにしているという理解(Relu関数)\n","        h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\n","\n","    # プーリング層1の作成\n","    # 2*2の枠を作り、その枠内の特徴を1*1分にいい感じに圧縮させている。\n","    # その枠を2*2ずつスライドさせて画像全体に対して圧縮作業を適用するという理解\n","    # ざっくり理解で細分化された特徴たちをもうちょっといい感じに大まかにまとめる(圧縮する)\n","    with tf.name_scope('pool1') as scope:\n","        h_pool1 = max_pool_2x2(h_conv1)\n","\n","    # 畳み込み層第2レイヤーの作成\n","    with tf.name_scope('conv2') as scope:\n","        # 第1レイヤーでの出力を第2レイヤー入力にしてもう一度フィルタリング実施。\n","        # 64個の特徴を検出する。inputが32なのは第1レイヤーの出力と一致させてる。\n","        W_conv2 = weight_variable([5, 5, 32, 64])\n","        # バイアスの数値を代入(第一レイヤーと同じ)\n","        b_conv2 = bias_variable([64])\n","        # 検出した特徴の整理(第一レイヤーと同じ)\n","        h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n","\n","    # プーリング層2の作成(ブーリング層1と同じ)\n","    with tf.name_scope('pool2') as scope:\n","        h_pool2 = max_pool_2x2(h_conv2)\n","        \n","    # 畳み込み層第3レイヤーの作成\n","    with tf.name_scope('conv3') as scope:\n","        W_conv3 = weight_variable([5, 5, 64, 128])\n","        b_conv3 = bias_variable([128])\n","        h_conv3 = tf.nn.relu(conv2d(h_pool2, W_conv3) + b_conv3)\n","\n","    # プーリング層2の作成(ブーリング層1と同じ)\n","    with tf.name_scope('pool3') as scope:\n","        h_pool3 = max_pool_2x2(h_conv3)\n","\n","    # 全結合層1の作成\n","    with tf.name_scope('fc1') as scope:\n","        W_fc1 = weight_variable([7*7*128, 1024])\n","        b_fc1 = bias_variable([1024])\n","        # 画像の解析を結果をベクトルへ変換\n","        h_pool3_flat = tf.reshape(h_pool3, [-1, 7*7*128])\n","        # 第一、第二と同じく、検出した特徴を活性化させている\n","        h_fc1 = tf.nn.relu(tf.matmul(h_pool3_flat, W_fc1) + b_fc1)\n","        # dropoutの設定\n","        # 訓練用データだけに最適化して、実際にあまり使えないような\n","        # AIになってしまう「過学習」を防止の役割を果たすらしい\n","        h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n","\n","    # 全結合層2の作成(読み出しレイヤー)\n","    with tf.name_scope('fc2') as scope:\n","        W_fc2 = weight_variable([1024, NUM_CLASSES])\n","        b_fc2 = bias_variable([NUM_CLASSES])\n","\n","    # ソフトマックス関数による正規化\n","    # ここまでのニューラルネットワークの出力を各ラベルの確率へ変換する\n","    with tf.name_scope('softmax') as scope:\n","        y_conv=tf.nn.softmax(tf.matmul(h_fc1_drop, W_fc2) + b_fc2)\n","\n","    # 各ラベルの確率(のようなもの?)を返す\n","    return y_conv\n","\n","# 予測結果と正解にどれくらい「誤差」があったかを算出する\n","# logitsは計算結果:  float - [batch_size, NUM_CLASSES]\n","# labelsは正解ラベル: int32 - [batch_size, NUM_CLASSES]\n","def loss(logits, labels):\n","    # 交差エントロピーの計算\n","    # 普通に計算するとlog0になる可能性があるため正規化している\n","    cross_entropy = -tf.reduce_sum(labels*tf.log(logits+1e-7))\n","    # TensorBoardで表示するよう指定\n","    tf.summary.scalar(\"cross_entropy\", cross_entropy)\n","    # 誤差の率の値(cross_entropy)を返す\n","    return cross_entropy\n","\n","# 誤差(loss)を元に誤差逆伝播を用いて設計した学習モデルを訓練する\n","# 裏側何が起きているのかよくわかってないが、学習モデルの各層の重み(w)などを\n","# 誤差を元に最適化して調整しているという理解(?)\n","# (誤差逆伝播は「人工知能は人間を超えるか」書籍の説明が神)\n","def training(loss, learning_rate):\n","    #この関数がその当たりの全てをやってくれる様\n","    train_step = tf.train.AdamOptimizer(learning_rate).minimize(loss)\n","    return train_step\n","\n","# inferenceで学習モデルが出した予測結果の正解率を算出する\n","def accuracy(logits, labels):\n","    # 予測ラベルと正解ラベルが等しいか比べる。同じ値であればTrueが返される\n","    # argmaxは配列の中で一番値の大きい箇所のindex(=一番正解だと思われるラベルの番号)を返す\n","    correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(labels, 1))\n","    # booleanのcorrect_predictionをfloatに直して正解率の算出\n","    # false:0,true:1に変換して計算する\n","    accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n","    # TensorBoardで表示する様設定\n","    tf.summary.scalar(\"accuracy\", accuracy)\n","    return accuracy\n","\n","def shuffleDict(d):\n","    keys = list(d.keys())\n","    random.shuffle(keys)\n","    keys = [(key, d[key]) for key in keys]\n","    return dict(keys)\n","  \n","if __name__ == '__main__':\n","    # ファイルを開く\n","    filelist = json.load(open(train_data, 'r'))\n","    filelist = shuffleDict(filelist)\n","    # データを入れる配列\n","    train_image = []\n","    train_label = []\n","    for filepath in filelist.keys():\n","        # データを読み込む\n","        img = cv2.imread(filepath)\n","        img = cv2.resize(img, (IMAGE_SIZE, IMAGE_SIZE))\n","        # 一列にした後、0-1のfloat値にする\n","        train_image.append(img.flatten().astype(np.float32)/255.0)\n","        # ラベルを1-of-k方式で用意する\n","        tmp = np.zeros(NUM_CLASSES)\n","        tmp[filelist[filepath]] = 1\n","        train_label.append(tmp)\n","    # numpy形式に変換\n","    train_image = np.asarray(train_image)\n","    train_label = np.asarray(train_label)\n","\n","    # ファイルを開く\n","    filelist = json.load(open(test_data, 'r'))\n","    # データを入れる配列\n","    test_image = []\n","    test_label = []\n","    for filepath in filelist.keys():\n","        # データを読み込む\n","        img = cv2.imread(filepath)\n","        img = cv2.resize(img, (IMAGE_SIZE, IMAGE_SIZE))\n","        # 一列にした後、0-1のfloat値にする\n","        test_image.append(img.flatten().astype(np.float32)/255.0)\n","        # ラベルを1-of-k方式で用意する\n","        tmp = np.zeros(NUM_CLASSES)\n","        tmp[filelist[filepath]] = 1\n","        test_label.append(tmp)\n","    # numpy形式に変換\n","    test_image = np.asarray(test_image)\n","    test_label = np.asarray(test_label)\n","\n","    #TensorBoardのグラフに出力するスコープを指定\n","    with tf.Graph().as_default():\n","        # 画像を入れるためのTensor(28*28*3(IMAGE_PIXELS)次元の画像が任意の枚数(None)分はいる)\n","        images_placeholder = tf.placeholder(\"float\", shape=(None, IMAGE_PIXELS))\n","        # ラベルを入れるためのTensor(3(NUM_CLASSES)次元のラベルが任意の枚数(None)分入る)\n","        labels_placeholder = tf.placeholder(\"float\", shape=(None, NUM_CLASSES))\n","        # dropout率を入れる仮のTensor\n","        keep_prob = tf.placeholder(\"float\")\n","\n","        # inference()を呼び出してモデルを作る\n","        logits = inference(images_placeholder, keep_prob)\n","        # loss()を呼び出して損失を計算\n","        loss_value = loss(logits, labels_placeholder)\n","        # training()を呼び出して訓練して学習モデルのパラメーターを調整する\n","        train_op = training(loss_value, learning_rate)\n","        # 精度の計算\n","        acc = accuracy(logits, labels_placeholder)\n","\n","        # 保存の準備\n","        saver = tf.train.Saver()\n","        # Sessionの作成(TensorFlowの計算は絶対Sessionの中でやらなきゃだめ)\n","        sess = tf.Session()\n","        # 変数の初期化(Sessionを開始したらまず初期化)\n","        sess.run(tf.global_variables_initializer())\n","        # TensorBoard表示の設定(TensorBoardの宣言的な?)\n","        summary_op = tf.summary.merge_all()\n","        # train_dirでTensorBoardログを出力するpathを指定\n","        summary_writer = tf.summary.FileWriter(train_dir, sess.graph)\n","\n","        step = 0\n","        print(len(train_image))\n","        # 無限に訓練を実行していく\n","        while True:\n","            for i in range(len(train_image)//batch_size):\n","                # batch_size分の画像に対して訓練の実行\n","                batch = batch_size*i\n","                # feed_dictでplaceholderに入れるデータを指定する\n","                sess.run(train_op, feed_dict={\n","                    images_placeholder: train_image[batch:batch+batch_size],\n","                    labels_placeholder: train_label[batch:batch+batch_size],\n","                    keep_prob: 0.5})\n","\n","            # 1step終わるたびに精度を計算する\n","            train_accuracy = sess.run(acc, feed_dict={\n","                images_placeholder: train_image,\n","                labels_placeholder: train_label,\n","                keep_prob: 1.0})\n","            if step % 5 == 0:\n","                print(\"step {}, training accuracy {}\".format(step, train_accuracy))\n","                if train_accuracy == 1.0:\n","                    break\n","\n","            # 1step終わるたびにTensorBoardに表示する値を追加する\n","            summary_str = sess.run(summary_op, feed_dict={\n","                images_placeholder: train_image,\n","                labels_placeholder: train_label,\n","                keep_prob: 1.0})\n","            summary_writer.add_summary(summary_str, step)\n","            \n","            # 100stepごとにテストデータで精度チェック\n","            if step > 1 and step % 100 == 0:\n","                test_accuracy = sess.run(acc, feed_dict={\n","                    images_placeholder: test_image,\n","                    labels_placeholder: test_label,\n","                    keep_prob: 1.0})\n","                print(\"test accuracy {}\".format(test_accuracy))\n","                if test_accuracy > 0.96:\n","                    break\n","            step += 1\n","\n","    # データを学習して最終的に出来上がったモデルを保存\n","    # \"model.ckpt\"は出力されるファイル名\n","    save_path = saver.save(sess, \"./drive/imas_model.ckpt\")"],"execution_count":11,"outputs":[{"output_type":"stream","text":["7723\n","step 0, training accuracy 0.11239156126976013\n","step 5, training accuracy 0.2117052972316742\n","step 10, training accuracy 0.3559497594833374\n","step 15, training accuracy 0.4995467960834503\n","step 20, training accuracy 0.5964003801345825\n","step 25, training accuracy 0.7308040857315063\n","step 30, training accuracy 0.8090120553970337\n","step 35, training accuracy 0.8404765129089355\n","step 40, training accuracy 0.8578272461891174\n","step 45, training accuracy 0.876731812953949\n","step 50, training accuracy 0.8939531445503235\n","step 55, training accuracy 0.9097501039505005\n","step 60, training accuracy 0.9232163429260254\n","step 65, training accuracy 0.9320212602615356\n","step 70, training accuracy 0.9413440227508545\n","step 75, training accuracy 0.9491130113601685\n","step 80, training accuracy 0.9553282260894775\n","step 85, training accuracy 0.9597306847572327\n","step 90, training accuracy 0.9638741612434387\n","step 95, training accuracy 0.9664638042449951\n","step 100, training accuracy 0.9708662629127502\n","test accuracy 0.9235751032829285\n","step 105, training accuracy 0.9739738702774048\n","step 110, training accuracy 0.9766929745674133\n","step 115, training accuracy 0.9774699211120605\n","step 120, training accuracy 0.980318546295166\n","step 125, training accuracy 0.9805774688720703\n","step 130, training accuracy 0.9827787280082703\n","step 135, training accuracy 0.9838145971298218\n","step 140, training accuracy 0.9847209453582764\n","step 145, training accuracy 0.9851093888282776\n","step 150, training accuracy 0.986015796661377\n","step 155, training accuracy 0.9874401092529297\n","step 160, training accuracy 0.9867926836013794\n","step 165, training accuracy 0.9879580736160278\n","step 170, training accuracy 0.9888644218444824\n","step 175, training accuracy 0.9886054396629333\n","step 180, training accuracy 0.9892528653144836\n","step 185, training accuracy 0.9893823862075806\n","step 190, training accuracy 0.9895118474960327\n","step 195, training accuracy 0.9895118474960327\n","step 200, training accuracy 0.9888644218444824\n","test accuracy 0.9507771730422974\n","step 205, training accuracy 0.9900297522544861\n","step 210, training accuracy 0.9900297522544861\n","step 215, training accuracy 0.9900297522544861\n","step 220, training accuracy 0.9902887344360352\n","step 225, training accuracy 0.9902887344360352\n","step 230, training accuracy 0.9900297522544861\n","step 235, training accuracy 0.9904182553291321\n","step 240, training accuracy 0.9908066987991333\n","step 245, training accuracy 0.9905477166175842\n","step 250, training accuracy 0.9909361600875854\n","step 255, training accuracy 0.9908066987991333\n","step 260, training accuracy 0.9910656213760376\n","step 265, training accuracy 0.9909361600875854\n","step 270, training accuracy 0.9905477166175842\n","step 275, training accuracy 0.9913246035575867\n","step 280, training accuracy 0.9914541244506836\n","step 285, training accuracy 0.9914541244506836\n","step 290, training accuracy 0.9910656213760376\n","step 295, training accuracy 0.9914541244506836\n","step 300, training accuracy 0.9908066987991333\n","test accuracy 0.9559585452079773\n","step 305, training accuracy 0.9913246035575867\n"],"name":"stdout"},{"output_type":"stream","text":["step 310, training accuracy 0.9913246035575867\n","step 315, training accuracy 0.9911951422691345\n","step 320, training accuracy 0.9911951422691345\n","step 325, training accuracy 0.9913246035575867\n","step 330, training accuracy 0.9909361600875854\n","step 335, training accuracy 0.9913246035575867\n","step 340, training accuracy 0.9910656213760376\n","step 345, training accuracy 0.9917130470275879\n","step 350, training accuracy 0.9913246035575867\n","step 355, training accuracy 0.9917130470275879\n","step 360, training accuracy 0.9909361600875854\n","step 365, training accuracy 0.9911951422691345\n","step 370, training accuracy 0.9915835857391357\n","step 375, training accuracy 0.9914541244506836\n","step 380, training accuracy 0.9915835857391357\n","step 385, training accuracy 0.9909361600875854\n","step 390, training accuracy 0.9914541244506836\n","step 395, training accuracy 0.9911951422691345\n","step 400, training accuracy 0.9911951422691345\n","test accuracy 0.9598445892333984\n","step 405, training accuracy 0.9911951422691345\n","step 410, training accuracy 0.9913246035575867\n","step 415, training accuracy 0.9917130470275879\n","step 420, training accuracy 0.991972029209137\n","step 425, training accuracy 0.9913246035575867\n","step 430, training accuracy 0.9915835857391357\n","step 435, training accuracy 0.9915835857391357\n","step 440, training accuracy 0.9917130470275879\n","step 445, training accuracy 0.9915835857391357\n","step 450, training accuracy 0.9915835857391357\n","step 455, training accuracy 0.9918425679206848\n","step 460, training accuracy 0.9915835857391357\n","step 465, training accuracy 0.9914541244506836\n","step 470, training accuracy 0.9910656213760376\n","step 475, training accuracy 0.9913246035575867\n","step 480, training accuracy 0.9921014904975891\n","step 485, training accuracy 0.9913246035575867\n","step 490, training accuracy 0.9923604726791382\n","step 495, training accuracy 0.9918425679206848\n","step 500, training accuracy 0.991972029209137\n","test accuracy 0.9611399173736572\n"],"name":"stdout"}]},{"metadata":{"id":"_ZaPMcPbjD3y","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"output_extras":[{"item_id":1}],"base_uri":"https://localhost:8080/","height":36},"outputId":"87ceb02f-89c1-4a6c-8f84-981857047b56","executionInfo":{"status":"ok","timestamp":1521787085172,"user_tz":-540,"elapsed":4286,"user":{"displayName":"赤西マロン","photoUrl":"//lh6.googleusercontent.com/-KhUeandtJaM/AAAAAAAAAAI/AAAAAAAAAEk/QrbgcTNc53o/s50-c-k-no/photo.jpg","userId":"112493323667235130589"}}},"cell_type":"code","source":["!google-drive-ocamlfuse -cc\n","!rm files/study.json\n","!cp drive/study.json files/"],"execution_count":8,"outputs":[{"output_type":"stream","text":["Clearing cache...done\r\n"],"name":"stdout"}]},{"metadata":{"id":"98xJQKzbw7aZ","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["!cp drive/files.tar ./\n","!mkdir files\n","!tar xf files.tar -C files"],"execution_count":0,"outputs":[]},{"metadata":{"id":"1BdoP3z4HDYx","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"output_extras":[{"item_id":1}],"base_uri":"https://localhost:8080/","height":36},"outputId":"de722ef5-c555-4aa0-aaca-89439e024d5e","executionInfo":{"status":"ok","timestamp":1521786524521,"user_tz":-540,"elapsed":817,"user":{"displayName":"赤西マロン","photoUrl":"//lh6.googleusercontent.com/-KhUeandtJaM/AAAAAAAAAAI/AAAAAAAAAEk/QrbgcTNc53o/s50-c-k-no/photo.jpg","userId":"112493323667235130589"}}},"cell_type":"code","source":["!ls"],"execution_count":2,"outputs":[{"output_type":"stream","text":["datalab  drive\r\n"],"name":"stdout"}]}]}